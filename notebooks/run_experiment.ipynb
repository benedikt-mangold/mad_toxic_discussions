{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a702d014-1ab0-4f3a-8e51-f61d9e5d595b",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c183a32-d4bf-4062-88f6-8cd95f0e7855",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "import urllib3\n",
    "import traceback\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from random import choice, seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0b3594",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b06d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.generate_persona import generate_agent_pool_pro, generate_agent_pool_con\n",
    "from src.connectors import parse_request_and_execute\n",
    "from src.debate import start_debate, next_debate_round, next_debate_round_toxic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bcd72b6-880b-4df0-9eaa-e1343a4671f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to disable verification of certificate, this removes the re-occuring warnings \n",
    "urllib3.disable_warnings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aacd7a2-4d1b-420e-ba74-277a1f95d9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace with your ollama server url\n",
    "url = \"https://xxxxx/llm/ollama/llama3.1-405b/v1/chat/completions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae774db-ba68-4b46-8cbd-49ab7e5a688f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add file with authentification token\n",
    "# with open('./conf/auth.txt', 'r') as file:\n",
    "#    token = file.read()\n",
    "token = input()\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f15a3d0-f256-42d9-8aca-df05c6e701ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {token}\",\n",
    "    \"Content-Type\": \"application/json\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50661099-28a4-4601-a781-867131a550ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "options_dict = {\n",
    "    \"temperature\": 0,\n",
    "    \"seed\": 42\n",
    "}\n",
    "n_agents = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fa62748-049a-493f-a1f6-f8b922b384db",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'./data/debate_topics.json', 'r') as fp:\n",
    "    topics = json.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2081686c",
   "metadata": {},
   "source": [
    "# Generate Personas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb48bddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for topic_ix, proposition in enumerate(topics.keys()):\n",
    "    topic_nr = topic_ix + 1\n",
    "    \n",
    "    file_path = f'./data/pool_of_{n_agents}_debate_pro_agents_for_topic_{topic_nr}.json'\n",
    "    #if topic_nr == 1:\n",
    "    #    continue\n",
    "\n",
    "    if os.path.isfile(file_path):\n",
    "        print(f\"pro-pool for topic nr. {topic_nr} already exists at {file_path} - {proposition}\")\n",
    "    else:\n",
    "    \n",
    "        print(f\"processing pro-pool for topic nr. {topic_nr} - {proposition}\")\n",
    "    \n",
    "        start_time = time.time()\n",
    "\n",
    "        response = parse_request_and_execute(\n",
    "            generate_agent_pool_pro(proposition, n_agents), \n",
    "            url, \n",
    "            headers, \n",
    "            options_dict, \n",
    "            max_retries=5,\n",
    "            delay=60\n",
    "        )\n",
    "    \n",
    "        total_time = time.time() - start_time\n",
    "        print(f\"--- Topic {topic_nr}: {total_time / 60:.2f} minutes --- {proposition}\")\n",
    "        \n",
    "        pool_of_pro_debate_agents = [\n",
    "            json.loads((\"{\" + resp.split(\"}\")[0].split(\" (modified to) \")[0] + \"}\").strip())\n",
    "            for resp in \n",
    "            response.json()[\"choices\"][0][\"message\"][\"content\"].split(\"{\")\n",
    "            if \"}\" in resp\n",
    "        ]\n",
    "        \n",
    "        with open(file_path, 'w') as fp:\n",
    "            json.dump(pool_of_pro_debate_agents, fp)\n",
    "\n",
    "    file_path = f'./data/pool_of_{n_agents}_debate_con_agents_for_topic_{topic_nr}.json'\n",
    "\n",
    "    if os.path.isfile(file_path):\n",
    "        print(f\"con-pool for topic nr. {topic_nr} already exists at {file_path} - {proposition}\")\n",
    "    else:\n",
    "    \n",
    "        print(f\"processing con-pool for topic nr. {topic_nr} - {proposition}\")\n",
    "    \n",
    "        start_time = time.time()\n",
    "    \n",
    "        response = parse_request_and_execute(\n",
    "            generate_agent_pool_con(proposition, n), \n",
    "            url, \n",
    "            headers, \n",
    "            options_dict, \n",
    "            max_retries=5,\n",
    "            delay=60\n",
    "        )\n",
    "    \n",
    "        total_time = time.time() - start_time\n",
    "        print(f\"--- Topic {topic_nr}: {total_time / 60:.2f} minutes --- {proposition}\")\n",
    "        \n",
    "        pool_of_con_debate_agents = [\n",
    "            json.loads((\"{\" + resp.split(\"}\")[0].split(\" (modified to) \")[0] + \"}\").strip())\n",
    "            for resp in \n",
    "            response.json()[\"choices\"][0][\"message\"][\"content\"].split(\"{\")\n",
    "            if \"}\" in resp\n",
    "        ]\n",
    "        \n",
    "        with open(file_path, 'w') as fp:\n",
    "            json.dump(pool_of_con_debate_agents, fp)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf7adac",
   "metadata": {},
   "source": [
    "# Debate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29fccf4-d7d8-430f-8a53-39a5ae59f7ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discussion 9 , proposition We should block access to social messaging networks during riots\n",
      "'Getting first argument (con) --- \n"
     ]
    }
   ],
   "source": [
    "seed(42)\n",
    "N = 1000\n",
    "n = 10\n",
    "\n",
    "for j in range(1, N+1):\n",
    "    topic_ix, proposition = choice(list(enumerate(topics.keys())))\n",
    "    topic_nr = topic_ix + 1\n",
    "\n",
    "    file_path = f'./data/pool_of_{n}_debate_con_agents_for_topic_{topic_nr}.json'\n",
    "    with open(file_path, 'r') as fp:\n",
    "        pool_of_con_debate_agents = json.load(fp)\n",
    "\n",
    "    file_path = f'./data/pool_of_{n}_debate_pro_agents_for_topic_{topic_nr}.json'\n",
    "    with open(file_path, 'r') as fp:\n",
    "        pool_of_pro_debate_agents = json.load(fp)\n",
    "    \n",
    "    print(\"discussion\", j, \", proposition\", proposition)\n",
    "\n",
    "    \n",
    "    for toxicity_level in [\"no\", \"mild\", \"moderate\", \"heavy\"]:\n",
    "        \n",
    "        debate_missing = True\n",
    "        i = 0\n",
    "        # initialize discussion\n",
    "        while debate_missing:\n",
    "            try:\n",
    "                debate = start_debate(\n",
    "                    proposition=proposition, \n",
    "                    topic_ix=topic_ix, \n",
    "                    topic_nr=topic_nr, \n",
    "                    pool_of_con_debate_agents=pool_of_con_debate_agents, \n",
    "                    n_con_agents=1, \n",
    "                    pool_of_pro_debate_agents=pool_of_pro_debate_agents, \n",
    "                    n_pro_agents=1\n",
    "                )\n",
    "                # not missing anymore\n",
    "                debate_missing = False\n",
    "            except Exception as e:\n",
    "                print(\"failed:\", type(e).__name__, \"–\", e)\n",
    "            i += 1\n",
    "            if i > 100:\n",
    "                break\n",
    "    \n",
    "        # preparing discussion\n",
    "        \n",
    "        \n",
    "        pro_or_con_toxic = choice([\"pro\", \"con\"])\n",
    "        print(\"pro_or_con_toxic\", pro_or_con_toxic)\n",
    "        \n",
    "        print(\"toxicity_level\", toxicity_level)\n",
    "        debate[\"pro_or_con_toxic\"] = pro_or_con_toxic\n",
    "        \n",
    "        \n",
    "        if toxicity_level == \"no\":\n",
    "            i = 0\n",
    "            still_arguing = True\n",
    "            # running discussion\n",
    "            while still_arguing:\n",
    "                try:\n",
    "                    debate = next_debate_round(debate)\n",
    "                    # still_arguing = False\n",
    "                    file_path = f'./data/toxic_and_baseline_random/discussion_{j}_round_{i}_for_topic_{topic_nr}_neither_toxic_level_{toxicity_level}.json'\n",
    "                    with open(file_path, 'w') as fp:\n",
    "                        json.dump(debate, fp)\n",
    "                    if debate[\"in_alignment\"]:\n",
    "                        # then it would be over\n",
    "                        still_arguing = False\n",
    "                except Exception as e:\n",
    "                    print(\"failed:\", type(e).__name__, \"–\", e)\n",
    "                    print(traceback.format_exc())\n",
    "                    # response_content is a global variable set in next_debate_round_toxic\n",
    "                    print(response_content)\n",
    "                    debate[\"nrounds\"] =  debate[\"nrounds\"] - 1\n",
    "                i += 1\n",
    "                if i > 100:\n",
    "                    break\n",
    "        else:  \n",
    "            i = 0\n",
    "            still_arguing = True\n",
    "            # running discussion\n",
    "            while still_arguing:\n",
    "                try:\n",
    "                    debate = next_debate_round_toxic(debate, pro_or_con_toxic, toxicity_level=toxicity_level)\n",
    "                    # still_arguing = False'\n",
    "                    file_path = f'./data/toxic_and_baseline_random/discussion_{j}_round_{i}_for_topic_{topic_nr}_{pro_or_con_toxic}_toxic_level_{toxicity_level}.json'\n",
    "                    with open(file_path, 'w') as fp:\n",
    "                        json.dump(debate, fp)\n",
    "                    if debate[\"in_alignment\"]:\n",
    "                        # then it would be over\n",
    "                        still_arguing = False\n",
    "                except Exception as e:\n",
    "                    print(\"failed:\", type(e).__name__, \"–\", e)\n",
    "                    print(traceback.format_exc())\n",
    "                    # response_content is a global variable set in next_debate_round_toxic\n",
    "                    print(response_content)\n",
    "                    debate[\"nrounds\"] =  debate[\"nrounds\"] - 1\n",
    "                i += 1\n",
    "                if i > 100:\n",
    "                    break\n",
    "        print(\"\")\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
